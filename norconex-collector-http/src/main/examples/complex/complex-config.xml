<!-- 
Copyright 2010-2013 Norconex Inc.

This file is part of Norconex HTTP Collector.

Norconex HTTP Collector is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

Norconex HTTP Collector is distributed in the hope that it will be useful, 
but WITHOUT ANY WARRANTY; without even the implied warranty of 
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with Norconex HTTP Collector. If not, see <http://www.gnu.org/licenses/>.
-->
<?xml version="1.0" encoding="UTF-8"?>
<httpcollector id="Complex Crawl">

  #set($basepkg = "com.norconex.collector.http")
  #set($normalizer = "$basepkg.handler.impl.GenericURLNormalizer")
  #set($extension = "$basepkg.filter.impl.ExtensionURLFilter")
  #set($urlRegex = "$basepkg.filter.impl.RegexURLFilter")
  
  <progressDir>$workdir\progress</progressDir>
  <logsDir>$workdir\logs</logsDir>

  <crawlerDefaults>

    <urlNormalizer class="$normalizer" />
    <numThreads>2</numThreads>
    <depth>1</depth>
    <workDir>$workdir</workDir>
    <deleteOrphans>true</deleteOrphans>

    <httpURLFilters>
      <filter class="$extension" onMatch="exclude">jpg,gif,png,ico,css,js</filter>
      <filter class="$urlRegex">http://en.wikipedia.com/wiki/.*</filter>
      <filter class="$urlRegex" onMatch="exclude">.*:.*</filter>
    </httpURLFilters>

  </crawlerDefaults>

  <crawlers>

    <crawler id="Alice Crawl">
      <startURLs>
        <url>http://en.wikipedia.org/wiki/Alice%27s_Adventures_in_Wonderland</url>
      </startURLs>
      #parse("shared/importer-config.xml")
      <committer class="com.norconex.committer.FileSystemCommitter">
        <directory>$workdir\AliceCrawledFiles</directory>
      </committer>
    </crawler>

    <crawler id="Wizard of Oz Crawl">
      <startURLs>
        <url>http://en.wikipedia.org/wiki/The_Wonderful_Wizard_of_Oz</url>
      </startURLs>
      #parse("shared/importer-config.xml")
      <committer class="com.norconex.committer.FileSystemCommitter">
        <directory>$workdir\OzCrawledFiles</directory>
      </committer>

    </crawler>

  </crawlers>

</httpcollector>