<!-- 
Copyright 2010-2013 Norconex Inc.

This file is part of Norconex HTTP Collector.

Norconex HTTP Collector is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

Norconex HTTP Collector is distributed in the hope that it will be useful, 
but WITHOUT ANY WARRANTY; without even the implied warranty of 
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with Norconex HTTP Collector. If not, see <http://www.gnu.org/licenses/>.
-->
<?xml version="1.0" encoding="UTF-8"?>
<!-- This configuration shows the minimum required and minimum recommended to 
     run a crawler.  
     -->
<httpcollector id="Minimal Config HTTP Collector">

  <crawlers>
    <crawler id="Minimal Config Wikipedia 1-page Crawl">

      <!-- === Minimum required: =========================================== -->

      <!-- Requires at least one start URL. -->
      <startURLs>
        <url>http://en.wikipedia.org/wiki/Alice%27s_Adventures_in_Wonderland</url>
      </startURLs>

      <!-- === Minimum recommended: ======================================== -->

      <!-- Put a maximum depth to avoid infinite crawling (e.g. calendars). -->
      <depth>0</depth>

      <!-- Be as nice as you can to sites you crawl. -->
      <delay default="5000" />
      
      <!-- At a minimum make sure you stay on your domain. -->
      <httpURLFilters>
        <filter 
            class="com.norconex.collector.http.filter.impl.RegexURLFilter"
            onMatch="include" >
          http://en\.wikipedia\.org/wiki/.*
        </filter>
      </httpURLFilters>
      
      <!-- Decide what to do with your files by specifying a committer. -->
      <committer class="com.norconex.committer.FileSystemCommitter">
        <directory>./minimunCrawlFiles</directory>
      </committer>

    </crawler>
  </crawlers>

</httpcollector>